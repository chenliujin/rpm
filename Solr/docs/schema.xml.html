<style>
	* {
		line-height: 1.5em;
	}
	#content {
		padding: 2em;
		width: 80%;
		min-width: 500px;
		max-width: 794px;
		border: 1px solid #ccc;
	}
	#content h1 {
		font-size: 1.8em;
	}	
	#content h2 {
		font-size: 1.2em;
	}
	#content h3 {
		font-size: 1.4em;
	}
	#content pre {
		padding: 0.5em 1em;
		border: 1pt solid #AEBDCC;
		background-color: #F3F5F7;
		overflow: hidden;
	}
</style>

<div id="content">
	<p>schema.xml的配置直接影响搜索结果的准确性与效率。</p>
	
	
<h1>fields</h1>

<ul>
	<li>
		<strong>name</strong>
		<p>字段名称</p>
	</li>
	<li>
		<strong>type</strong>
		<p>字段类型</p>
	</li>
	<li>
		<strong>indexed=true|false</strong>
		<p>True if this field should be "indexed". If (and only if) a field is indexed, then it is searchable, sortable, and facetable.</p>
	</li>
	<li>
		<strong>stored=true|false</strong>
		<p>满足查询条件时，是否返回该字段的内容</p>
	</li>
	<li>
		<strong>required</strong>
		<p>required 是否是必须字段，如若是，该字段必须有值，否则索引报错</p>
	</li>
	<li>
		<strong>multiValued</strong>
		<p>是否为多值类型，SOLR允许配置多个数据源字段存储到一个搜索字段中。多个值必须为true，否则有可能抛出异常。</p>
	</li>
	<li>
		<strong>omitNorms=true|false</strong>
		<p>一般文本字段不设置为true。我们可以通过将 omitNorms="true" 来减少 indexed fields 数量增加所带来的影响</p>
	</li>
</ul>

<h2>Dynamic fields</h2>
<p>假设 schema 中定义了一个叫 *_i 的动态字段，当要索引一个叫 cost_i 的字段时，如果 schema 中未定义 cost_i 的字段，那么将会按照 *_i 的规则创建 cost_i 字段。</p>
<p>One of the powerful features of Lucene is that you don't have to pre-define every field when you first create your index. Even though Solr provides strong datatyping for fields, it still preserves that flexibility using "Dynamic Fields". Using <dynamicField> declarations, you can create field rules that Solr will use to understand what datatype should be used whenever it is given a field name that is not explicitly defined, but matches a prefix or suffix used in a dynamicField.</p>
<p>For example the following dynamic field declaration tells Solr that whenever it sees a field name ending in "_i" which is not an explicitly defined field, then it should dynamically create an integer field with that name...</p>
<pre>&lt;dynamicField name="*_i" type="integer" indexed="true" stored="true"/&gt;</pre>

<h1>copyField</h1>
<p>复制相关联的字段到目标字段，搜索的时候就可以不用很复杂的查询组合就可以在目标字段中进行搜索</p>
<ul>
	<li><strong>source</strong></li>
	<li><strong>dest</strong></li>
	<li>
		<strong>maxChars</strong>
		<p>限制复制的最大长度</p>
	</li>
</ul>

<p>把所有字段放在一起：</p>
<pre>
&lt; copyField source = "*" dest = "text_t" /&gt;
</pre>

<h1>fieldType</h1>
<ul>
	<li>
		<strong>name</strong>
		<p></p>
	</li>
	<li>
		<strong>class</strong>
		<p></p>
	</li>
	<li>
		<strong>sortMissingLast=true|false，默认=false</strong>
		<p>sortMissingLast="true"，没有该field的数据排在有该field的数据之后，而不管请求时的排序规则，在Java中对应的意思就是，该字段为NULL，排在后面。</p>
	</li>
	<li>
		<strong>sortMissingFirst</strong>
		<p>sortMissingFirst="true"，排序规则与sortMissingLast相反。</p>
	</li>
	<li>
		<strong>positionIncrementGap</strong>
		<p></p>
	</li>
	<li>
		<p><strong>tokenizer</strong></p>
		<p>分词器</p>
	</li>
	<li>
		<strong>filter</strong>
		<p>过滤器</p>
		<ul>
			<li>
				<p>solr.StopFilterFactory</p>
				<p>停用词，不需要匹配的词</p>
			</li>
			<li>
				<p><strong>solr.SynonymFilterFactory</strong></p>
				<p>同义词</p>
			</li>
			<li>
				<p>solr.LowerCaseFilterFactory</p>
				<p>忽略大小写</p>
			</li>
			<li>
				<p><strong>solr.PorterStemFilterFactory</strong></p>
				<p>采用 Porter Stemming Algorithm 算法去掉单词的后缀，例如将复数形式变成单数形式，第三人称动词变成第一人称，现在分词变成一般现在时的动词。它是原生的英语Porter算法，它比SnowBall的速度快一倍</p>
			</li>			
			<li>
				<p><strong>solr.SnowballPorterFilterFactory</strong></p>
				<p>这个词干器允许选择多种词干器算法，这些词干器算法是由一个名为Snowball的程序产生的。你可以在language属性中指定你要选择的词干器。指定为English会使用Porter2算法，它比原生的Porter的算法有一点点改进。指定为Lovins会使用Lovins算法，它比起Porter有一些改进，但是运行速度太慢。</p>
			</li>
			<li>
				<p>solr.RemoveDuplicatesTokenFilterFactory</p>
				<p>避免重复处理。</p>
			</li>
		</ul>
	</li>
	<li>
		<strong>charFilter</strong>
		<p>和其它 CharFilters 一样，在 schema.xml 文件中，使用 charFilter 标记进行指定，且必须出现在 tokenizer 前面。</p>
		<ul>
			<li>
				<strong>solr.HTMLStripCharFilterFactory</strong>
				<p>该过滤器能够将 HTML 标记从输入流中脱去并将结果传递给其它 CharFilter 或者 Tokenizer。</p>
			</li>
		</ul>
	</li>
</ul>

<h2>定义</h2>

<ul>
	<li>
		<strong>string</strong>
		<p>string 类型的 class 是 solr.StrField，不会被分词。</p>
	</li>
	<li>boolean</li>
	<li>int</li>
	<li>float</li>
	<li>long</li>
	<li>double</li>
	<li>tint</li>
	<li>tfloat</li>
	<li>tlong</li>
	<li>tdouble</li>
	<li>date</li>
	<li>tdate</li>
	<li>binary</li>
	<li>random</li>
	<li>text_ws</li>
	<li>managed_en</li>
	<li>text_general</li>
	<li>
		<p><strong>text_en</strong></p>
		
<pre>&lt;fieldType name=&quot;text_en&quot; class=&quot;solr.TextField&quot; positionIncrementGap=&quot;100&quot;&gt;
	&lt;analyzer type=&quot;index&quot;&gt;
		...
		<s>&lt;filter class=&quot;solr.PorterStemFilterFactory&quot;/&gt;</s>
		&lt;filter class=&quot;solr.SnowballPorterFilterFactory&quot; language=&quot;English&quot;/&gt;
		&lt;filter class=&quot;solr.WordDelimiterFilterFactory&quot; generateWordParts=&quot;1&quot; generateNumberParts=&quot;1&quot; 
			catenateWords=&quot;1&quot; catenateNumbers=&quot;1&quot; catenateAll=&quot;0&quot; splitOnCaseChange=&quot;1&quot;/&gt;
		&lt;filter class=&quot;solr.RemoveDuplicatesTokenFilterFactory&quot;/&gt;
	&lt;/analyzer&gt; </pre>
	</li>
	<li>text_en_splitting</li>
	<li><strong>text_en_splitting_little</strong></li>
	<li>text_en_splitting_tight</li>
	<li>text_general_rev</li>
	<li>alphaOnlySort</li>
	<li>phonetic</li>
	<li>payloads</li>
	<li>lowercase</li>
	<li>descendent_path</li>
	<li>ancestor_path</li>
	<li>ignored</li>
	<li>point</li>
	<li>location</li>
	<li>location_rpt</li>
	<li>bbox</li>
	<li>_bbox_coord</li>
	<li>currency</li>
	<li>text_ar</li>
	<li>text_bg</li>
	<li>text_ca</li>
	<li>text_cjk</li>
	<li>text_ckb</li>
	<li>text_cz</li>
	<li>text_da</li>
	<li>text_de</li>
	<li>text_el</li>
	<li>text_es</li>
	<li>text_eu</li>
	<li>text_fa</li>
	<li>text_fi</li>
	<li>text_fr</li>
	<li>text_ga</li>
	<li>text_gl</li>
	<li>text_hi</li>
	<li>text_hu</li>
	<li>text_hy</li>
	<li>text_id</li>
	<li>text_it</li>
	<li>text_ja</li>
	<li>text_lv</li>
	<li>text_nl</li>
	<li>text_no</li>
	<li>text_pt</li>
	<li>text_ro</li>
	<li>text_ru</li>
	<li>text_sv</li>
	<li>text_th</li>
	<li>text_tr</li>
</ul>

<h3>WordDelimiterFilter</h3>
<p>这个过滤器可以通过多种配置指定如切分和连接合成词，并有多种定义合成词的方法。这个过滤器通常与 WhitespaceTokenizer 配合，而不是 StandardTokenizer。这个过滤器的配置中 1 是设置，0 是重置。WordDelimiterFilter 先通过配置选项中的定义切分词元（示例中右边以逗号分隔是处理后的词）：</p>
<ul>
	<li>
		<p>词间的分隔符切分：Wi-Fi 切为 Wi，Fi</p>
	</li>
	<li>
		<p>忽略任何分隔符：/hello―there, dude 切为 hello, there, dude</p>
	</li>
	<li>
		<p><strong>splitOnCaseChange=1</strong></p>
		<p>大小写变换时进行切分，WiFi 切为 Wi，Fi</p>
	</li>
	<li>
		<p><strong>splitOnNumerics=1</strong></p>
		<p>字母和数据间的切分：SD500 切为 SD，500</p>
	</li>
	<li>
		<p><strong>stemEnglishPocessive=1</strong></p>
		<p>移除所有格’s：David’s切为Divid</p>
	</li>
	<li>
		<p><strong><em>generateWordParts=1</em></strong></p>
		<p>全是字母的字元将被保留下来进行索引，未设置或设置为 0 时，切分后的字母字元会被过滤掉，不进行索引。</p>
	</li>
	<li>
		<p><strong><em>generateNumberParts=1</em></strong></p>
		<p>全是数字的字元将被保留下来进行索引，未设置或设置为 0 时，切分后的数字字元会被过滤掉，不进行索引。</p>
	</li>	
	<li>
		<p><strong>catenateWords=1</strong></p>
		<p>连接多个全字母的词元，比如 wi-fi 连接为 wifi</p>
	</li>
	<li>
		<p><strong>catenateNumbers</strong></p>
		<p>连接多个全数字的词元，比如 802.11 连接为 80211</p>
	</li>
	<li>
		<p><strong>catenateAll</strong></p>
		<p>catenateAll会考虑连接所有的词到一起，比如 WiFi-802.11b 连接为 WiFi80211b</p>
	</li>
	<li>
		<p><strong>preserveOriginal=1</strong></p>
		<p>保留原始的词</p>
	</li>
</ul>

<p>内部实现中，过滤器在寻找单词边界前对每个字符赋予一个类型（比如：字母，数字）。这个类型是由Unicode字符类型决定的。如果你想自定义过滤器对字符的类型归类，你可以在type选项中提供一个或多个映射文件。一个实现的例子是在Twitter中，你想将”#”和”@”视为类型ALPHA。要了解这个难解的特性，可以看SOLR-2059。</p>
<p>如果有一些词，你不想用过滤器处理，你可以在procected属性中指定包括这些词的配置文件。其它一些过滤器也有相似的特性。</p>
<p>在Solr的text_en_splitting域类型中使用WordDelimiterFilter是一个合理的方式：在索引和查询的时候都产生词和数字，但只在索引时进行连接操作，因为在查询时进行连接是多余的。</p>


<h1>参考文献</h1>
<ul>
	<li><a href="https://wiki.apache.org/solr/SchemaXml" target="_blank">https://wiki.apache.org/solr/SchemaXml</a></li>
	<li><a href="https://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters" target="_blank">https://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters</a></li>
</ul>

</div>